{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEX\n",
    "\n",
    "-  [MODELING, loadING, EVOLVING](#modeling-loading-evolving)\n",
    "\n",
    "    1. [Modeling](#modeling)\n",
    "\n",
    "    2. [loading](#loading)\n",
    "\n",
    "    3. [Evolving](#evolving)\n",
    "\n",
    "- [QUERYING](#querying)\n",
    "    \n",
    "    1. [Query 1](#query-1:-find-the-top-3-most-cited-papers-of-each-conference.)\n",
    "\n",
    "    2. [Query 2](#query-2:-for-each-conference-find-its-community:-i.e.,-those-authors-that-have-published-papers-on-that-conference-in,-at-least,-4-different-editions.)\n",
    "\n",
    "    3. [Query 3](#query-3:-find-the-impact-factors-of-the-journals-in-your-graph.)\n",
    "\n",
    "    4. [Query 4](#query-4:-find-the-h-indexes-of-the-authors-in-your-graph.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"gwaB$3DMlab2\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING, loadING, EVOLVING\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "faker = Faker()\n",
    "\n",
    "num_authors = 100\n",
    "num_papers = 200\n",
    "num_conferences = 5\n",
    "num_journals = 3\n",
    "num_topics = 10\n",
    "num_keywords = 50\n",
    "num_reviews_per_paper = 3\n",
    "num_venues = 20\n",
    "num_years = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Authors\n",
    "authors = [\n",
    "    {\n",
    "        \"name\": faker.name(),\n",
    "        \"affiliation\": faker.company()\n",
    "    }\n",
    "    for _ in range(num_authors)\n",
    "]\n",
    "\n",
    "# Generate Topics and Keywords\n",
    "topics = [{\"topic_name\": faker.word()} for _ in range(num_topics)]\n",
    "keywords = [{\"word\": faker.word(), \"topic\": random.choice(topics)[\"topic_name\"]} for _ in range(num_keywords)]\n",
    "\n",
    "# Generate Venues\n",
    "venues = [{\"city\": faker.city()} for _ in range(num_venues)]\n",
    "\n",
    "# Generate Years\n",
    "years = [str(year) for year in range(1970, 1970 + num_years)]\n",
    "\n",
    "# Generate Papers\n",
    "papers = []\n",
    "for _ in range(num_papers):\n",
    "    num_authors_per_paper = random.randint(1, 5)\n",
    "    author_list = random.sample(authors, k=num_authors_per_paper)\n",
    "    corresponding_author = random.choice(author_list)\n",
    "    num_keywords_per_paper = random.randint(1, 10)\n",
    "    keyword_list = random.sample(keywords, k=num_keywords_per_paper)\n",
    "    paper = {\n",
    "        \"title\": faker.sentence(nb_words=6),\n",
    "        \"abstract\": faker.paragraph(nb_sentences=3),\n",
    "        \"year\": random.choice(years),\n",
    "        \"pages\": random.randint(1, 20),\n",
    "        \"DOI\": faker.uuid4(),\n",
    "        \"authors\": author_list,\n",
    "        \"corresponding_author\": corresponding_author,\n",
    "        \"keywords\": keyword_list\n",
    "    }\n",
    "    papers.append(paper)\n",
    "\n",
    "# Generate Conferences and Editions\n",
    "conferences = [{\"name\": f\"Conference {i+1}\"} for i in range(num_conferences)]\n",
    "\n",
    "editions = []\n",
    "for conf in conferences:\n",
    "    num_editions = random.randint(1, 20)\n",
    "    starting_year = random.randint(1970, 1970 + num_years - num_editions)\n",
    "    for i in range(num_editions):\n",
    "        edition = {\n",
    "            \"conference_name\": conf[\"name\"],\n",
    "            \"attendees\": random.randint(100, 1000),\n",
    "            \"venue\": random.choice(venues)[\"city\"],\n",
    "            \"year\": str(starting_year + i)\n",
    "        }\n",
    "        editions.append(edition)\n",
    "\n",
    "# Generate Journals and Volumes\n",
    "journals = [{\"name\": f\"Journal {i+1}\"} for i in range(num_journals)]\n",
    "\n",
    "volumes = []\n",
    "for journal in journals:\n",
    "    num_volumes = random.randint(1, 20)\n",
    "    for i in range(num_volumes):\n",
    "        volume = {\n",
    "            \"volume_number\": i + 1,\n",
    "            \"pages\": random.randint(50, 300)\n",
    "        }\n",
    "        volumes.append(volume)\n",
    "\n",
    "# Generate Reviews as Relationships\n",
    "reviews = []\n",
    "for paper in papers:\n",
    "    eligible_reviewers = [author for author in authors if author not in paper[\"authors\"]]\n",
    "    reviewers = random.sample(eligible_reviewers, k=num_reviews_per_paper)\n",
    "    for reviewer in reviewers:\n",
    "        review = {\n",
    "            \"paper_DOI\": paper[\"DOI\"],\n",
    "            \"reviewer_name\": reviewer[\"name\"]\n",
    "        }\n",
    "        reviews.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faked data generated and saved to faked_data.json.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"authors\": authors,\n",
    "    \"papers\": papers,\n",
    "    \"conferences\": conferences,\n",
    "    \"editions\": editions,\n",
    "    \"journals\": journals,\n",
    "    \"volumes\": volumes,\n",
    "    \"keywords\": keywords,\n",
    "    \"topics\": topics,\n",
    "    \"reviews\": reviews,\n",
    "    \"venues\": venues,\n",
    "    \"years\": [{\"year\": year} for year in years]\n",
    "}\n",
    "\n",
    "# Save to json file for safekeeping\n",
    "with open(\"faked_data.json\", \"w\") as f:\n",
    "    json.dump(data, f, indent=4)\n",
    "\n",
    "print(\"Faked data generated and saved to faked_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save keywords\u001b[39;00m\n\u001b[1;32m     10\u001b[0m keywords \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m keywords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mkeywords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m keywords\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save venues\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/bse/lib/python3.12/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/bse/lib/python3.12/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/bse/lib/python3.12/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/bse/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/bse/lib/python3.12/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2917\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Save keywords\u001b[39;00m\n\u001b[1;32m     10\u001b[0m keywords \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 11\u001b[0m keywords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m keywords[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtopic_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     12\u001b[0m keywords\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeywords.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save venues\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "\"\"\" we convert the json file to csv \"\"\"\n",
    "\n",
    "# Save authors\n",
    "pd.DataFrame(data['authors']).to_csv('authors.csv', index=False)\n",
    "\n",
    "# Save topics\n",
    "pd.DataFrame(data['topics']).to_csv('topics.csv', index=False)\n",
    "\n",
    "# Save keywords\n",
    "keywords = pd.DataFrame(data['keywords'])\n",
    "keywords['topic'] = keywords['topic'].apply(lambda x: x['topic_name'])\n",
    "keywords.to_csv('keywords.csv', index=False)\n",
    "\n",
    "# Save venues\n",
    "pd.DataFrame(data['venues']).to_csv('venues.csv', index=False)\n",
    "\n",
    "# Save years\n",
    "pd.DataFrame(data['years']).to_csv('years.csv', index=False)\n",
    "\n",
    "# Save papers\n",
    "papers = pd.DataFrame(data['papers'])\n",
    "papers.to_csv('papers.csv', index=False)\n",
    "\n",
    "# Save paper authors\n",
    "paper_authors = []\n",
    "for paper in data['papers']:\n",
    "    for author in paper['authors']:\n",
    "        paper_authors.append({'DOI': paper['DOI'], 'author_name': author['name']})\n",
    "pd.DataFrame(paper_authors).to_csv('paper_authors.csv', index=False)\n",
    "\n",
    "# Save corresponding authors\n",
    "paper_corresponding_authors = []\n",
    "for paper in data['papers']:\n",
    "    paper_corresponding_authors.append({'DOI': paper['DOI'], 'corresponding_author': paper['corresponding_author']['name']})\n",
    "pd.DataFrame(paper_corresponding_authors).to_csv('paper_corresponding_authors.csv', index=False)\n",
    "\n",
    "# Save paper keywords\n",
    "paper_keywords = []\n",
    "for paper in data['papers']:\n",
    "    for keyword in paper['keywords']:\n",
    "        paper_keywords.append({'DOI': paper['DOI'], 'keyword': keyword['word']})\n",
    "pd.DataFrame(paper_keywords).to_csv('paper_keywords.csv', index=False)\n",
    "\n",
    "# Save conferences\n",
    "pd.DataFrame(data['conferences']).to_csv('conferences.csv', index=False)\n",
    "\n",
    "# Save editions\n",
    "editions = pd.DataFrame(data['editions'])\n",
    "editions.to_csv('editions.csv', index=False)\n",
    "\n",
    "# Save journals\n",
    "pd.DataFrame(data['journals']).to_csv('journals.csv', index=False)\n",
    "\n",
    "# Save volumes\n",
    "volumes = pd.DataFrame(data['volumes'])\n",
    "volumes.to_csv('volumes.csv', index=False)\n",
    "\n",
    "# Save reviews\n",
    "reviews = pd.DataFrame(data['reviews'])\n",
    "reviews.to_csv('reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_database(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "def load_data(tx):\n",
    "    # Load Authors\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///authors.csv' AS row\n",
    "    CREATE (:Author {name: row.name, affiliation: row.affiliation});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Topics\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///topics.csv' AS row\n",
    "    CREATE (:Topic {topic_name: row.topic_name});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Keywords\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///keywords.csv' AS row\n",
    "    MATCH (t:Topic {topic_name: row.topic})\n",
    "    CREATE (:Keyword {word: row.word})-[:BELONGS_TO_TOPIC]->(t);\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Venues\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///venues.csv' AS row\n",
    "    CREATE (:Venue {city: row.city});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Years\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///years.csv' AS row\n",
    "    CREATE (:Year {year: row.year});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Papers\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///papers.csv' AS row\n",
    "    CREATE (p:Paper {title: row.title, abstract: row.abstract, year: row.year, pages: row.pages, DOI: row.DOI});\n",
    "    \"\"\")\n",
    "\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///paper_authors.csv' AS row\n",
    "    MATCH (p:Paper {DOI: row.DOI}), (a:Author {name: row.author_name})\n",
    "    CREATE (p)-[:AUTHORED_BY]->(a);\n",
    "    \"\"\")\n",
    "\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///paper_corresponding_authors.csv' AS row\n",
    "    MATCH (p:Paper {DOI: row.DOI}), (a:Author {name: row.corresponding_author})\n",
    "    CREATE (p)-[:CORRESPONDING_AUTHOR]->(a);\n",
    "    \"\"\")\n",
    "\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///paper_keywords.csv' AS row\n",
    "    MATCH (p:Paper {DOI: row.DOI}), (k:Keyword {word: row.keyword})\n",
    "    CREATE (p)-[:HAS_KEYWORD]->(k);\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Conferences\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///conferences.csv' AS row\n",
    "    CREATE (:Conference {name: row.name});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Editions\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///editions.csv' AS row\n",
    "    MATCH (c:Conference {name: row.conference_name}), (v:Venue {city: row.venue}), (y:Year {year: row.year})\n",
    "    CREATE (e:Edition {conference_name: row.conference_name, attendees: row.attendees})-[:HELD_AT]->(v)-[:HELD_IN_YEAR]->(y)-[:PUBLISHED_IN_EDITION]->(c);\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Journals\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///journals.csv' AS row\n",
    "    CREATE (:Journal {name: row.name});\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Volumes\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///volumes.csv' AS row\n",
    "    MATCH (j:Journal {name: row.journal_name}), (y:Year {year: row.year})\n",
    "    CREATE (v:Volume {volume_number: row.volume_number, pages: row.pages})-[:PUBLISHED_IN_YEAR]->(y)-[:PUBLISHED_IN_JOURNAL]->(j);\n",
    "    \"\"\")\n",
    "\n",
    "    # Load Reviews\n",
    "    tx.run(\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///reviews.csv' AS row\n",
    "    MATCH (p:Paper {DOI: row.paper_DOI}), (a:Author {name: row.reviewer_name})\n",
    "    CREATE (p)-[:REVIEWED_BY]->(a);\n",
    "    \"\"\")\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Clear the database\n",
    "    session.write_transaction(clear_database)\n",
    "\n",
    "    # Load the data\n",
    "    session.write_transaction(load_data)\n",
    "\n",
    "print(\"Data loaded into Neo4j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolving\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUERYING\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 1: Find the top 3 most cited papers of each conference.\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2: For each conference find its community: i.e., those authors that have published papers on that conference in, at least, 4 different editions.\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3: Find the impact factors of the journals in your graph.\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 4: Find the h-indexes of the authors in your graph.\n",
    "\n",
    "[Back to Index](#INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
